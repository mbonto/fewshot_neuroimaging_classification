{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from data import get_dataloader\n",
    "from utils import create_sampler\n",
    "import numpy as np\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data parameters\n",
    "IBC_path = '/bigdisk2/nilearn_data/neurovault/collection_6618/'\n",
    "split_dir = '../dataset/split/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline: nearest class mean in the input space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute similarities between two sets of vectors using the Euclidean distance.\n",
    "def simi_score(X, Y):\n",
    "    \"\"\"\n",
    "    Return a score between 0 and 1 (0 for very similar, 1 for not similar at all)\n",
    "    between all vectors in X and all vectors in Y.\n",
    "    \n",
    "    Parameters:\n",
    "        X -- set of vectors (number of vectors, vector size).\n",
    "        Y -- set of vectors (number of vectors, vector size).\n",
    "    \"\"\"\n",
    "    X = X / torch.norm(X, dim=1, keepdim=True)\n",
    "    Y = Y / torch.norm(Y, dim=1, keepdim=True)\n",
    "    distances = torch.cdist(Y, X, p=2)\n",
    "    similarities = 1 - torch.exp(-1*distances)\n",
    "    return similarities\n",
    "\n",
    "# Evaluate a model on the validation / test set.\n",
    "def episodic_evaluation(data_loader, sampler_infos, use_cuda):\n",
    "    \"\"\"\n",
    "    Return the average accuracy on few-shot tasks (called episodes).\n",
    "    A task contains training samples with known labels and query\n",
    "    samples. The accuracy is the number of times we correctly\n",
    "    predict the labels of the query samples.\n",
    "    \n",
    "    A label is represented by its training examples. A new sample\n",
    "    is labeled in function of the closest label-representative.\n",
    "    \"\"\"\n",
    "    n_way = sampler_infos[1]\n",
    "    n_shot = sampler_infos[2]\n",
    "    epoch_acc = 0.\n",
    "    total = 0.\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Iterate over several episodes.\n",
    "        for i, (x, y) in enumerate(data_loader):\n",
    "            # print(i, end='\\r')\n",
    "            if use_cuda:\n",
    "                x = x.cuda()\n",
    "                y = y.cuda()\n",
    "            # Adapt the shape of the input.\n",
    "            x = x.view(x.shape[0], -1)\n",
    "            # Split the data into training samples and query samples.\n",
    "            # Be careful: the data have to be sorted by split (train/query) and by classes. \n",
    "            training = x[:n_way*n_shot]\n",
    "            query = x[n_way*n_shot:]\n",
    "            train_labels = y[:n_way*n_shot]\n",
    "            query_labels = y[n_way*n_shot:]\n",
    "            del x\n",
    "\n",
    "            # Compute the vector representative of each class.\n",
    "            training = training.reshape(n_way, n_shot, -1).mean(1)\n",
    "            train_labels = train_labels[::n_shot]\n",
    "\n",
    "            # Find the labels of the query samples.\n",
    "            scores = simi_score(training, query)\n",
    "            pred_labels = torch.argmin(scores, dim=1)\n",
    "            pred_labels = torch.take(train_labels, pred_labels)\n",
    "            del training, query\n",
    "            \n",
    "            # Compute the accuracy.\n",
    "            acc = (query_labels == pred_labels).float().sum()\n",
    "            epoch_acc += acc\n",
    "            total += query_labels.size(0)\n",
    "    return epoch_acc / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The baseline has an average accuracy of 57.33% over 10000 tasks with 95% confidence interval 0.20.\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the baseline on the test set of parcellated images.\n",
    "# Episodes parameters\n",
    "parcel = True\n",
    "n_episode = 10000\n",
    "n_way = 5\n",
    "n_shot = 1\n",
    "n_query = 15\n",
    "test_sampler_infos = [1, n_way, n_shot, n_query]\n",
    "# Loader\n",
    "test_loader = get_dataloader('test', IBC_path, parcel, split_dir, meta=True, sampler_infos=test_sampler_infos)\n",
    "\n",
    "epoch_accs = []\n",
    "for i in range(n_episode):\n",
    "    print(i, end='\\r')\n",
    "    epoch_acc = episodic_evaluation(test_loader, test_sampler_infos, use_cuda=True)\n",
    "    epoch_accs.append(epoch_acc.cpu().item())\n",
    "mean, conf = compute_confidence_interval(epoch_accs)\n",
    "print('The baseline has an average accuracy of {:.2f}% over {} tasks with 95% confidence interval {:.2f}.'.format(mean*100, n_episode, conf*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myriam",
   "language": "python",
   "name": "myriam"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
