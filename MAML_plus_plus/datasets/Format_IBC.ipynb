{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "To execute the MAML++ code, all images need to be stored in a folder in a particular way.\n",
    "Thus, to use directly the code of MAML++, we need to copy the images in folders as follows:\n",
    "\n",
    "Dataset\n",
    "    ||\n",
    " ___||_________\n",
    "|       |     |\n",
    "train   val  test\n",
    "|_________________________\n",
    "    |       |            |\n",
    " class_0 class_1 ... class_N\n",
    "    |       |___________________\n",
    "    |                           |\n",
    "samples for class_0    samples for class_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import nilearn\n",
    "import nilearn.datasets\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###TO UPDATE\n",
    "# Path where the parcellated images are stored.\n",
    "data_dir = '/bigdisk2/nilearn_data/'\n",
    "# Retrieve the split files (train, val, test).\n",
    "split_path = '../../dataset/split'\n",
    "# Path to the formated dataset.\n",
    "save_path = './IBC'\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the IBC dataset\n",
    "data = nilearn.datasets.fetch_neurovault_ids(collection_ids=[6618], data_dir=data_dir)\n",
    "data_path = os.path.join(data_dir, 'neurovault/collection_6618/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_an_empty_folder(save_path, folder_name):\n",
    "    if os.path.exists(f'{save_path}/{folder_name}'):\n",
    "        shutil.rmtree(f'{save_path}/{folder_name}')\n",
    "    os.mkdir(f'{save_path}/{folder_name}')\n",
    "\n",
    "def classes_per_split(split, split_path):\n",
    "    data = load_csv_to_pd(f'{split_path}/{split}.csv')\n",
    "    classes = data.Label.unique()\n",
    "    return classes\n",
    "\n",
    "def load_csv_to_pd(filename):\n",
    "    data = pd.read_csv(filename)\n",
    "    return data\n",
    "\n",
    "def make_dir(save_path, folder_name, subfolders_names):\n",
    "    for name in subfolders_names:\n",
    "        os.mkdir(f'{save_path}/{folder_name}/{name}')\n",
    "\n",
    "def download_images(split_path, data_path, save_path, data):\n",
    "    \"\"\"\n",
    "    Put the images of IBC in IBC folder, sorted by split and by class.\n",
    "    \n",
    "    Parameters:\n",
    "        split_path -- path towards a folder containing train.csv, val.csv and test.csv.\n",
    "        data_path -- path in which the data are stored.\n",
    "        data -- nilearn dataset. here, nilearn.datasets.fetch_neurovault_ids(collection_ids=[6618]).\n",
    "        save_path -- path towards the folder IBC.\n",
    "    \"\"\"\n",
    "    # data:  Images and labels are accessible in nilearn.\n",
    "    # We retrieve the classes of each split.\n",
    "    train_classes = classes_per_split('train', split_path)\n",
    "    val_classes = classes_per_split('val', split_path)\n",
    "    test_classes = classes_per_split('test', split_path)\n",
    "    # We read all images once at a time.\n",
    "    # We look at the class of the image.\n",
    "    # If the class corresponds to the name of a subfolder, we add the image in the subfolder.\n",
    "    for i, meta in enumerate(data.images_meta):\n",
    "        # Retrieve the class name.\n",
    "        label = meta['contrast_definition']\n",
    "        # Retrieve the actual path towards the parcellated image stored in a npz format.\n",
    "        image_name = os.path.split(meta['relative_path'])[1]\n",
    "        image_path = os.path.join(f'{data_path}', image_name)\n",
    "        parcellation_path = os.path.splitext(os.path.splitext(image_path)[0])[0]+'.npz'\n",
    "        # Only consider ap/pa images.\n",
    "        name = meta['name'].split('_')\n",
    "        if 'ffx' not in name:\n",
    "            if label in val_classes:\n",
    "                X = np.load(parcellation_path)['X']\n",
    "                # Save the npz file in the right subfolder.\n",
    "                image_number = parcellation_path.split('/')[-1]\n",
    "                np.savez_compressed(f'{save_path}/val/{label}/{image_number}', X=X)\n",
    "            elif label in train_classes:\n",
    "                X = np.load(parcellation_path)['X']\n",
    "                image_number = parcellation_path.split('/')[-1]\n",
    "                # Save the npz file in the right subfolder.\n",
    "                image_number = parcellation_path.split('/')[-1]\n",
    "                np.savez_compressed(f'{save_path}/train/{label}/{image_number}', X=X)\n",
    "            elif label in test_classes:\n",
    "                X = np.load(parcellation_path)['X']\n",
    "                # Save the npz file in the right subfolder.\n",
    "                image_number = parcellation_path.split('/')[-1]\n",
    "                np.savez_compressed(f'{save_path}/test/{label}/{image_number}', X=X)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the folders train, val, test are empty.\n",
    "# (Here, train is the base dataset, val the validation dataset and test, the novel dataset.)\n",
    "create_an_empty_folder(save_path, 'train')\n",
    "create_an_empty_folder(save_path, 'val')\n",
    "create_an_empty_folder(save_path, 'test')\n",
    "# Retrieve the list of classes in each split file.\n",
    "train_classes = classes_per_split('train', split_path)\n",
    "val_classes = classes_per_split('val', split_path)\n",
    "test_classes = classes_per_split('test', split_path)\n",
    "# In train, val, test create folders with the names of the classes.\n",
    "make_dir(save_path, 'train', train_classes)\n",
    "make_dir(save_path, 'val', val_classes)\n",
    "make_dir(save_path, 'test', test_classes)\n",
    "# Store the images in the folder named after their class. \n",
    "download_images(split_path, data_path, save_path, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n",
      "22\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "# Check the number of classes\n",
    "path = f\"{save_path}/train\"\n",
    "print(len(os.listdir(path)))\n",
    "path = f\"{save_path}/val\"\n",
    "print(len(os.listdir(path)))\n",
    "path = f\"{save_path}/test\"\n",
    "print(len(os.listdir(path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2573\n",
      "625\n",
      "650\n"
     ]
    }
   ],
   "source": [
    "# Check the number of images per split.\n",
    "def images_per_split(save_path, split):\n",
    "    path = f\"{save_path}/{split}\"\n",
    "    count = 0\n",
    "    for folder in os.listdir(path):\n",
    "        for file in os.listdir(f'{path}/{folder}'):\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "print(images_per_split(save_path, 'train'))\n",
    "print(images_per_split(save_path, 'val'))\n",
    "print(images_per_split(save_path, 'test'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myriam",
   "language": "python",
   "name": "myriam"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
